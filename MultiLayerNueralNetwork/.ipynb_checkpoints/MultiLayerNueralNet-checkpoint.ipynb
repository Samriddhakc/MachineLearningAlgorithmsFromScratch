{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy \n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "import sklearn.linear_model\n",
    "import sklearn.linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import import_ipynb\n",
    "from HelperFunctions import relu,sigmoid,loss,L2_loss,gradient_descent_with_momentum,gradient_descent_normal\n",
    "np.random.seed(1) # set a seed so that the results are consistent\n",
    "#from ipynb.fs.full.HelperFunctions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from matplotlib import pyplot\n",
    "from pandas import DataFrame\n",
    "# generate 2d classification dataset\n",
    "X, Y = make_blobs(n_samples=200, centers=2, n_features=2)\n",
    "# scatter plot, dots colored by class value\n",
    "df = DataFrame(dict(x=X[:,0], y=X[:,1], label=Y))\n",
    "colors = {0:'red', 1:'blue', 2:'green'}\n",
    "fig, ax = pyplot.subplots()\n",
    "grouped = df.groupby('label')\n",
    "for key, group in grouped:\n",
    "    group.plot(ax=ax, kind='scatter', x='x', y='y', label=key, color=colors[key])\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "       1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0,\n",
       "       1, 0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_to_test the algorithm\n",
    "'''from sklearn.datasets import load_iris\n",
    "data=load_iris()\n",
    "X=data.data\n",
    "Y=data.target'''\n",
    "#Y[Y>0]=1\n",
    "feature_mean=np.mean(X,axis=0)\n",
    "feature_SD=np.std(X,axis=0)\n",
    "X=(X-feature_mean)/feature_SD\n",
    "X\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(134, 2)\n",
      "(66, 2)\n",
      "(134,)\n",
      "(66,)\n"
     ]
    }
   ],
   "source": [
    "Y.reshape((Y.shape[0],1))\n",
    "x_train,x_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 134)\n",
      "(2, 66)\n",
      "(1, 134)\n",
      "(1, 66)\n"
     ]
    }
   ],
   "source": [
    "x_train=x_train.T\n",
    "x_test=x_test.T\n",
    "y_train=y_train.reshape((y_train.shape[0],1))\n",
    "y_train=y_train.T\n",
    "y_test=y_test.reshape((y_test.shape[0],1))\n",
    "y_test=y_test.T\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intialize Model Parameters\n",
    "\n",
    "class MultiLayerNueralNet():\n",
    "    \n",
    "    \n",
    "    def __init__(self,num_input,num_hidden,num_output):\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        intialize class  instance variables \n",
    "        Argument:\n",
    "        num_input -- size of the input layer\n",
    "        num_hidden -- size of the hidden layer\n",
    "        num_ouput -- size of the output layer\n",
    "        \n",
    "        \"\"\"\n",
    "        np.random.seed(2)\n",
    "        self.num_input=num_input\n",
    "        self.num_hidden=num_hidden\n",
    "        self.num_output=num_output\n",
    "        self.W1=np.random.rand(num_hidden,num_input)\n",
    "        self.W2=np.random.rand(num_output,num_hidden)*0.01\n",
    "        self.b1=np.zeros((num_hidden,1))\n",
    "        self.b2=np.zeros((num_output,1))\n",
    "        self.cache={\"Z1\": None,\"A1\": None,\"Z2\": None,\"A2\": None}\n",
    "        self.grad_cache={\"dW1\": None,\"dW2\": None,\"db1\": None,\"db2\": None}\n",
    "   \n",
    "    \n",
    "    def forward_propgation(self,X):\n",
    "        \n",
    "        #LINEAR->RELU->LINEAR->SIGMOID\n",
    "        \n",
    "        W1=self.W1\n",
    "        W2=self.W2\n",
    "        b1=self.b1\n",
    "        b2=self.b2\n",
    "        Z1=np.dot(W1,X)+b1\n",
    "        A1=relu(Z1)\n",
    "        Z2=np.dot(W2,A1)+b2\n",
    "        A2=sigmoid(Z2)\n",
    "        self.cache[\"Z1\"]=Z1\n",
    "        self.cache[\"A1\"]=A1\n",
    "        self.cache[\"Z2\"]=Z2\n",
    "        self.cache[\"A2\"]=A2\n",
    "        return A2\n",
    "    \n",
    "    def forward_propgation_for_grad_check(self,X,parameters):\n",
    "        \n",
    "        #LINEAR->RELU->LINEAR->SIGMOID\n",
    "        \n",
    "        W1=parameters[:self.W1.size].reshape(self.W1.shape)\n",
    "        W2=parameters[self.W1.size:self.W1.size+self.W2.size].reshape(self.W2.shape)\n",
    "        b1=parameters[self.W1.size+self.W2.size:self.W1.size+self.W2.size+self.b1.size].reshape(self.b1.shape)\n",
    "        b2=parameters[self.W1.size+self.W2.size+self.b1.size:self.W1.size+self.W2.size+self.b1.size+self.b2.size].reshape(self.b2.shape)\n",
    "        assert(W1.shape==self.W1.shape)\n",
    "        assert(W2.shape==self.W2.shape)\n",
    "        assert(b1.shape==self.b1.shape)\n",
    "        assert(b2.shape==self.b2.shape)\n",
    "       \n",
    "        Z1=np.dot(W1,X)+b1\n",
    "        A1=relu(Z1)\n",
    "        Z2=np.dot(W2,A1)+b2\n",
    "        A2=sigmoid(Z2)\n",
    "        self.cache[\"Z1\"]=Z1\n",
    "        self.cache[\"A1\"]=A1\n",
    "        self.cache[\"Z2\"]=Z2\n",
    "        self.cache[\"A2\"]=A2\n",
    "        return A2\n",
    "    \n",
    "    def backward_propagation(self,X,Y):\n",
    "        \n",
    "        #Y=np.eye(3)[Y.squeeze()].T\n",
    "        m=X.shape[1]\n",
    "        W1=self.W1\n",
    "        W2=self.W2\n",
    "        b1=self.b1\n",
    "        b2=self.b2\n",
    "        Z1=self.cache[\"Z1\"]\n",
    "        A1=self.cache[\"A1\"]\n",
    "        Z2=self.cache[\"Z2\"]\n",
    "        A2=self.cache[\"A2\"]\n",
    "        dZ2=(A2 - Y)\n",
    "        dW2=(1./m)*np.dot(dZ2,A1.T)\n",
    "        db2=(1./m)*np.sum(dZ2,axis=1, keepdims = True)\n",
    "        #dZ1=np.dot(W2.T,dZ2)*A1*(1-A1)\n",
    "        dZ1=np.multiply(np.dot(W2.T,dZ2),np.int64(A1 > 0))\n",
    "        dW1=(1./m)*np.dot(dZ1,X.T)\n",
    "        db1=(1./m)*np.sum(dZ1,axis=1, keepdims = True)\n",
    "        self.grad_cache[\"dW1\"]=dW1\n",
    "        self.grad_cache[\"dW2\"]=dW2\n",
    "        self.grad_cache[\"db1\"]=db1\n",
    "        self.grad_cache[\"db2\"]=db2\n",
    "         \n",
    "    def implement_gradient_check(self,X,y,epsilon=1e-7):\n",
    "        \n",
    "        grad_concat=np.concatenate((self.grad_cache[\"dW1\"].flatten(),self.grad_cache[\"dW2\"].flatten(),self.grad_cache[\"db1\"].flatten(),self.grad_cache[\"db2\"].flatten()))\n",
    "        grad_concat=grad_concat.reshape((grad_concat.shape[0],1))\n",
    "        grad_approx=np.zeros(grad_concat.size)\n",
    "        grad_approx=grad_approx.reshape((grad_approx.shape[0],1))\n",
    "        parameter_concat=np.concatenate((self.W1.flatten(),self.W2.flatten(),self.b1.flatten(),self.b2.flatten()))\n",
    "        parameter_concat=parameter_concat.reshape((parameter_concat.shape[0],1))\n",
    "        \n",
    "        \n",
    "        for i in range(parameter_concat.size): \n",
    "            \n",
    "            parameter_concat_plus=copy.copy(parameter_concat)\n",
    "            parameter_concat_minus=copy.copy(parameter_concat)\n",
    "            parameter_concat_plus[i]=parameter_concat_plus[i]+epsilon\n",
    "            parameter_concat_minus[i]=parameter_concat_minus[i]-epsilon\n",
    "            A_plus=self.forward_propgation_for_grad_check(X,parameter_concat_plus)\n",
    "            J_plus=loss(X.shape[1],A_plus,y)\n",
    "            A_minus=self.forward_propgation_for_grad_check(X,parameter_concat_minus)\n",
    "            J_minus=loss(X.shape[1],A_minus,y)\n",
    "            grad_approx[i][0]=(J_plus- J_minus)/(2*epsilon)\n",
    "            \n",
    "        difference=np.sqrt(np.sum(((grad_approx-grad_concat)**2)))\n",
    "        L2_1=np.sqrt(np.sum(((grad_approx)**2)))\n",
    "        L2_2=np.sqrt(np.sum(((grad_concat)**2)))\n",
    "        difference=difference/(L2_2+L2_1)\n",
    "        #print(\"the difference is\",difference)\n",
    "        return difference\n",
    "    \n",
    "    #def Adam():   \n",
    "    #def RMS prop \n",
    "    #gradient descent with momentum. \n",
    "    \n",
    "    def train(self,x_train,y_train,x_test,y_test,num_iterations,gradient_name,learning_rate=0.1):\n",
    "        \n",
    "        train_loss=[]\n",
    "        test_loss=[]\n",
    "        #y_train=np.eye(3)[y_train.squeeze()].T\n",
    "        #y_test=np.eye(3)[y_test.squeeze()].T\n",
    "        m_train=y_train.shape[1]\n",
    "        m_test=y_test.shape[1]\n",
    "        #one_hot_y=np.eye(3)[y_train]\n",
    "        for i in range(num_iterations):\n",
    "            \n",
    "            self.forward_propgation(x_train)\n",
    "            self.backward_propagation(x_train,y_train)\n",
    "            if(gradient_name==\"graident_descent\"):\n",
    "                params={\"W1\": self.W1,\"W2\": self.W2,\"b1\": self.b1,\"b2\": self.b2}\n",
    "                grad_params=self.grad_cache\n",
    "                W1,W2,b1,b2=gradient_descent_normal(grad_params,params,learning_rate)\n",
    "                self.W1=W1\n",
    "                self.W2=W2\n",
    "                self.b1=b1\n",
    "                self.b2=b2\n",
    "                \n",
    "            elif(gradient_name==\"graident_descent_with_momentum\"): \n",
    "                self.W1,self.W2,self.b1,self.b2=gradient_descent_with_momentum(self.grad_cache,self.cache,learning_rate)\n",
    "    \n",
    "            if((i%10)==0):\n",
    "                \n",
    "                print(\"The train loss in\"+ str(i)+\"iterations is\", loss(m_train,self.cache[\"A2\"],y_train))\n",
    "                train_loss.append(loss(m_train,self.cache[\"A2\"],y_train))\n",
    "                self.implement_gradient_check(x_train,y_train)\n",
    "                self.forward_propgation(x_test)\n",
    "                #print(\"The val loss in\"+ str(i)+\"iterations is\", L2_loss(m_test,self.cache[\"A2\"],y_test))\n",
    "                test_loss.append(loss(m_test,self.cache[\"A2\"],y_test))\n",
    "        return train_loss,test_loss\n",
    "    \n",
    "    def predict(self,x):\n",
    "        \n",
    "        y_pred=self.forward_propgation(x_test)[0][0]\n",
    "        if (y_pred>=0.5):\n",
    "                return 1\n",
    "        else: \n",
    "            return 0\n",
    "        \n",
    "    def accuracy(self,x,y,output_n):\n",
    "        y_pred=self.forward_propgation(x)\n",
    "        if (output_n==1):\n",
    "            y_pred[y_pred>=0.5]=1\n",
    "            y_pred[y_pred<0.5]=0\n",
    "            return  y_pred,(np.sum(y_pred==y)/y.size)*100\n",
    "        else:\n",
    "            y_pred=np.argmax(y_pred,axis=0)\n",
    "            return  y_pred,(np.sum(y_pred==y)/y.size)*100\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nueralnet=MultiLayerNueralNet(x_train.shape[0],100,1)\n",
    "A2=nueralnet.forward_propgation(x_train)\n",
    "nueralnet.backward_propagation(x_train,y_train)\n",
    "train_loss,test_loss=nueralnet.train(x_train,y_train,x_test,y_test,10000,\"graident_descent\")\n",
    "print(nueralnet.implement_gradient_check(x_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2_loss(y_train.shape[1],A2,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_loss,label=\"TrainLoss\")\n",
    "plt.plot(test_loss,label=\"ValidationLoss\")\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature=np.array([-1.14452391, -1.19360307])\n",
    "y_pred,accuracy=nueralnet.accuracy(x_test,y_test,1)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion Matrix \n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix,multilabel_confusion_matrix\n",
    "y_pred=y_pred.reshape((1,66))\n",
    "y_true = y_test\n",
    "fig, axes= plt.subplots(1,3,figsize=(10,5))\n",
    "conf_array=multilabel_confusion_matrix((np.squeeze(y_test)).tolist(), (np.squeeze(y_pred)).tolist(), labels=[0,1,2])\n",
    "label_maps={\"setosa\":0,\"veriscular\":1,\"virginica\":2}\n",
    "for index in range(len(conf_array)): \n",
    "    keys_list=list(label_maps.keys())\n",
    "    current_index_string=keys_list[list(label_maps.values()).index(index)]\n",
    "    df_cm = pd.DataFrame(conf_array[index], index = [i for i in ['not-'+current_index_string, current_index_string]],\n",
    "                      columns = [i for i in ['not-'+current_index_string, current_index_string]])\n",
    "    plt.figure(figsize = (10,10))\n",
    "    sn.heatmap(df_cm,ax=axes[index], annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "result_tuple=precision_recall_fscore_support((np.squeeze(y_test)).tolist(), (np.squeeze(y_pred)).tolist(), average='weighted')\n",
    "print(\"The Precision of the NueralNet for this dataset is\",result_tuple[0])\n",
    "print(\"The Recall of the NueralNet for this dataset is\",result_tuple[1])\n",
    "print(\"The F1 Score of the NueralNet for this dataset is\",result_tuple[2]) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
